{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 1,
    "id": "kr9vAeEQlRVG"
   },
   "source": [
    "# Домашнее задание 2. Классификация изображений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 3,
    "id": "BxX49gLclRVJ"
   },
   "source": [
    "В этом задании потребуется обучить классификатор изображений. Будем работать с датасетом, название которого раскрывать не будем. Можете посмотреть самостоятельно на картинки, которые в есть датасете. В нём 200 классов и около 5 тысяч картинок на каждый класс. Классы пронумерованы, как нетрудно догадаться, от 0 до 199. Скачать датасет можно вот [тут](https://yadi.sk/d/BNR41Vu3y0c7qA).\n",
    "\n",
    "Структура датасета простая -- есть директории train/ и val/, в которых лежат обучающие и валидационные данные. В train/ и val/ лежат директориии, соответствующие классам изображений, в которых лежат, собственно, сами изображения.\n",
    " \n",
    "__Задание__. Необходимо выполнить любое из двух заданий\n",
    "\n",
    "1) Добейтесь accuracy **на валидации не менее 0.44**. В этом задании **запрещено** пользоваться предобученными моделями и ресайзом картинок. \n",
    "\n",
    "2) Добейтесь accuracy **на валидации не менее 0.84**. В этом задании делать ресайз и использовать претрейн можно. \n",
    "\n",
    "Напишите краткий отчёт о проделанных экспериментах. Что сработало и что не сработало? Почему вы решили, сделать так, а не иначе? Обязательно указывайте ссылки на чужой код, если вы его используете. Обязательно ссылайтесь на статьи / блогпосты / вопросы на stackoverflow / видосы от ютуберов-машинлернеров / курсы / подсказки от Дяди Васи и прочие дополнительные материалы, если вы их используете. \n",
    "\n",
    "Ваш код обязательно должен проходить все `assert`'ы ниже.\n",
    "\n",
    "Необходимо написать функции `train_one_epoch`, `train` и `predict` по шаблонам ниже (во многом повторяют примеры с семинаров).Обратите особое внимание на функцию `predict`: она должна возвращать список лоссов по всем объектам даталоадера, список предсказанных классов для каждого объекта из даталоалера и список настоящих классов для каждого объекта в даталоадере (и именно в таком порядке).\n",
    "\n",
    "__Использовать внешние данные для обучения строго запрещено в обоих заданиях. Также запрещено обучаться на валидационной выборке__.\n",
    "\n",
    "\n",
    "__Критерии оценки__: Оценка вычисляется по простой формуле: `min(10, 10 * Ваша accuracy / 0.44)` для первого задания и `min(10, 10 * (Ваша accuracy - 0.5) / 0.34)` для второго. Оценка округляется до десятых по арифметическим правилам. Если вы выполнили оба задания, то берется максимум из двух оценок.\n",
    "\n",
    "__Бонус__. Вы получаете 5 бонусных баллов если справляетесь с обоими заданиями на 10 баллов (итого 15 баллов). В противном случае выставляется максимальная из двух оценок и ваш бонус равен нулю.\n",
    "\n",
    "__Советы и указания__:\n",
    " - Наверняка вам потребуется много гуглить о классификации и о том, как заставить её работать. Это нормально, все гуглят. Но не забывайте, что нужно быть готовым за скатанный код отвечать :)\n",
    " - Используйте аугментации. Для этого пользуйтесь модулем `torchvision.transforms` или библиотекой [albumentations](https://github.com/albumentations-team/albumentations)\n",
    " - Можно обучать с нуля или файнтюнить (в зависимости от задания) модели из `torchvision`.\n",
    " - Рекомендуем написать вам сначала класс-датасет (или воспользоваться классом `ImageFolder`), который возвращает картинки и соответствующие им классы, а затем функции для трейна по шаблонам ниже. Однако делать это мы не заставляем. Если вам так неудобно, то можете писать код в удобном стиле. Однако учтите, что чрезмерное изменение нижеперечисленных шаблонов увеличит количество вопросов к вашему коду и повысит вероятность вызова на защиту :)\n",
    " - Валидируйте. Трекайте ошибки как можно раньше, чтобы не тратить время впустую.\n",
    " - Чтобы быстро отладить код, пробуйте обучаться на маленькой части датасета (скажем, 5-10 картинок просто чтобы убедиться что код запускается). Когда вы поняли, что смогли всё отдебажить, переходите обучению по всему датасету\n",
    " - На каждый запуск делайте ровно одно изменение в модели/аугментации/оптимайзере, чтобы понять, что и как влияет на результат.\n",
    " - Фиксируйте random seed.\n",
    " - Начинайте с простых моделей и постепенно переходите к сложным. Обучение лёгких моделей экономит много времени.\n",
    " - Ставьте расписание на learning rate. Уменьшайте его, когда лосс на валидации перестаёт убывать.\n",
    " - Советуем использовать GPU. Если у вас его нет, используйте google colab. Если вам неудобно его использовать на постоянной основе, напишите и отладьте весь код локально на CPU, а затем запустите уже написанный ноутбук в колабе. Авторское решение задания достигает требуемой точности в колабе за 15 минут обучения.\n",
    " \n",
    "Good luck & have fun! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.11.1-cp38-cp38-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "     |████████████████████████████████| 1.2 MB 961 kB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy in ./lib/python3.8/site-packages (from torchvision) (1.21.3)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in ./lib/python3.8/site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: torch==1.10.0 in ./lib/python3.8/site-packages (from torchvision) (1.10.0)\n",
      "Requirement already satisfied: typing-extensions in ./lib/python3.8/site-packages (from torch==1.10.0->torchvision) (3.10.0.2)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "cell_id": 4,
    "id": "LKcSNj4tlRVK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# You may add any imports you need\n",
    "from torchvision.transforms import Compose, Normalize, Resize, ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RytEDW0ylRVN"
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uSqSsFg4lRVN"
   },
   "outputs": [],
   "source": [
    "# class MyDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, data_dir, transform):\n",
    "#         # YOUR CODE\n",
    "#         pass\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         # YOUR CODE\n",
    "#         pass\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         # YOUR CODE\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 5,
    "id": "QEdDQtHdlRVO"
   },
   "outputs": [],
   "source": [
    "train_transform = Compose(\n",
    "    [ToTensor(),\n",
    "     Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "val_transform = ToTensor()\n",
    "# YOU CAN DEFINE AUGMENTATIONS HERE\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=\"./dataset/dataset/train\", transform=train_transform)\n",
    "val_dataset = torchvision.datasets.ImageFolder(root=\"./dataset/dataset/val\", transform=val_transform)\n",
    "# REPLACE ./dataset/dataset WITH THE FOLDER WHERE YOU DOWNLOADED AND UNZIPPED THE DATASET\n",
    "# OR USE torchvision.datasets.ImageFolder INSTEAD OF MyDataset\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 6,
    "id": "mrg4Yj0VlRVP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests passed\n"
     ]
    }
   ],
   "source": [
    "# Just very simple sanity checks\n",
    "assert isinstance(train_dataset[0], tuple)\n",
    "assert len(train_dataset[0]) == 2\n",
    "assert isinstance(train_dataset[1][1], int)\n",
    "print(\"tests passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RlSlmyjlRVP"
   },
   "source": [
    "### Вспомогательные функции, реализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "cell_id": 7,
    "id": "yYG2-Cq8lRVQ"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataloader, criterion, optimizer, device=\"cuda:0\"):\n",
    "    model.train()\n",
    "    # YOUR CODE\n",
    "    # TRAIN YOUR MODEL HERE\n",
    "    # train_losses, train_acc = 0., 0., 0.\n",
    "    for imgs, labels in tqdm(train_dataloader, desc=f\"Training\",  leave=False):\n",
    "        # tensors go to device, where model is\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(imgs) # матрица уверенностей\n",
    "        loss = criterion(y_pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def predict(model, val_dataloder, criterion, device=\"cuda:0\"):\n",
    "    model.eval()\n",
    "    # YOUR CODE\n",
    "    losses = []\n",
    "    predicted_classes = []\n",
    "    true_classes = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(val_dataloader, leave=False):\n",
    "            # tensors go to device, where model is\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            pred = model(imgs)\n",
    "            loss = criterion(pred, labels)\n",
    "\n",
    "            losses.append(loss)\n",
    "            predicted_classes += torch.argmax(pred, dim=-1)\n",
    "            # predicted_classes.append(pred_classes)\n",
    "            true_classes += labels\n",
    "        \n",
    "    # PREDICT FOR EVERY ELEMENT OF THE VAL DATALOADER AND RETURN CORRESPONDING LISTS\n",
    "    return losses, predicted_classes, true_classes\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, device=\"cuda:0\", n_epochs=10, \n",
    "          scheduler=None):\n",
    "    model.to(device)\n",
    "    train_loss_log, train_acc_log, val_loss_log, val_acc_log = [], [], [], []\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f'Epoch: {epoch + 1}:')\n",
    "        train(model, train_dataloader, criterion, optimizer, device)\n",
    "        \n",
    "        train_losses, train_preds, train_classes = predict(model, train_dataloader, criterion, device)\n",
    "        train_acc = accuracy_sscore(train_preds, train_classes)\n",
    "        print(f'Train accuracy: {train_acc}')\n",
    "        \n",
    "        val_losses, val_preds, val_classes = predict(model, val_dataloader, criterion, device)\n",
    "        val_acc = accuracy_score(val_preds, val_classes)\n",
    "        print(f'Validation accuracy: {val_acc}')\n",
    "        \n",
    "        train_loss_log.append(train_losses.mean())\n",
    "        val_loss_log.append(val_losses.mean())\n",
    "        \n",
    "        train_acc_log.append(train_acc)\n",
    "        val_acc_log.append(val_acc)\n",
    "        \n",
    "    return train_loss_log, train_acc_log, val_loss_log, val_acc_log\n",
    "    # Train, evaluate, print accuracy, make a step of scheduler or whatever you want..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(dataset_item):\n",
    "    plt.imshow(np.transpose(dataset_item[0].numpy(), (1, 2, 0)), cmap='Greys')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxR3gfcilRVW"
   },
   "source": [
    "### Обучение модели, запуски экспериментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBaseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelBaseline, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1) # + relu\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=5, padding=2) # + relu\n",
    "        # max pool 2x2, s=2 + flatten\n",
    "        self.fc1 = nn.Linear(32 * 32 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, 200)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.flatten(self.pool(x))\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "cell_id": 8,
    "id": "JXFJ6oS8lRVX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ModelBaseline()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = None # LR SCHEDULE THAT YOU PROBABLY CHOOSE\n",
    "n_epochs = 10\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 9,
    "id": "CesoOl6BlRVY"
   },
   "source": [
    "Простой тест на проверку правильности написанного кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "cell_id": 10,
    "id": "B_LB2jn6lRVY"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests passed\n"
     ]
    }
   ],
   "source": [
    "all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\n",
    "assert len(predicted_labels) == len(val_dataset)\n",
    "accuracy = accuracy_score(predicted_labels, true_labels)\n",
    "print(\"tests passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 11,
    "id": "tS-LLiXUlRVY"
   },
   "source": [
    "Запустить обучение можно в ячейке ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 12,
    "id": "ECIzZ_RYlRVZ"
   },
   "outputs": [],
   "source": [
    "train(model, train_dataloader, val_dataloader, criterion, optimizer, device, n_epochs, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImVW8_EXlRVZ"
   },
   "source": [
    "### Проверка полученной accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 13,
    "id": "FmR-elhJlRVZ"
   },
   "source": [
    "После всех экспериментов которые вы проделали, выберите лучшую из своих моделей, реализуйте и запустите функцию `evaluate`. Эта функция должна брать на вход модель и даталоадер с валидационными данными и возврашать accuracy, посчитанную на этом датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 14,
    "id": "3TGH0EFalRVb"
   },
   "outputs": [],
   "source": [
    "all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\n",
    "assert len(predicted_labels) == len(val_dataset)\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(\"Оценка за это задание составит {} баллов\".format(min(5, 5 * accuracy / 0.44)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 15,
    "id": "pT8vfPSolRVb"
   },
   "source": [
    "### Отчёт об экспериментах \n",
    "\n",
    "текст писать тут"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw01_part2_tony_upd.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "max_cell_id": 35
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
